{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import energyflow as ef\n",
    "import ROOT\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ROOT.TFile(\"dataname.root\")\n",
    "t = f.Get(\"tree\")\n",
    "mc_f = ROOT.TFile(\"mcname.root\")\n",
    "mc_t = mc_f.Get(\"tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and MC jets into lists in order to use the energyflow package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jet list of data\n",
    "events = []\n",
    "# jet multiplicity of data\n",
    "jetm = []\n",
    "# jet pt of data\n",
    "pttot = []\n",
    "# for MC\n",
    "mc_events = []\n",
    "mc_jetm = []\n",
    "mc_pttot = []\n",
    "\n",
    "for e in t:\n",
    "    if e.jetm > 0:\n",
    "        n = e.jetm\n",
    "        if e.pt > 20: \n",
    "            ev = 1\n",
    "            jetm.append(n)\n",
    "            pttot.append(e.pt)\n",
    "        else: ev = 0\n",
    "        ls = []\n",
    "    elif n >= 0:\n",
    "        ls.append([e.pt, e.eta, e.phi])\n",
    "        n -= 1\n",
    "    if n == 0 and ev == 1:\n",
    "        events.append(ls)\n",
    "jetm = np.array(jetm)\n",
    "pttot = np.array(pttot)\n",
    "\n",
    "for e in mc_t:\n",
    "    if e.jetm > 0:\n",
    "        n = e.jetm\n",
    "        if e.pt > 20: \n",
    "            ev = 1\n",
    "            mc_jetm.append(n)\n",
    "            mc_pttot.append(e.pt)\n",
    "        else: ev = 0\n",
    "        ls = []\n",
    "    elif n >= 0:\n",
    "        ls.append([e.pt, e.eta, e.phi])\n",
    "        n -= 1\n",
    "    if n == 0 and ev == 1:\n",
    "        mc_events.append(ls)\n",
    "mc_jetm = np.array(mc_jetm)\n",
    "mc_pttot = np.array(mc_pttot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jet multiplicity lower bound = n for graphs containing n dots (used for excluding jets with jetm < #dots of EFP graph)\n",
    "jetm_lb = [ 2, \n",
    "            2, 3, \n",
    "            2, 3, 3, 4, 4, \n",
    "            2, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, \n",
    "            2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6]\n",
    "# the 53 EFP multigraphs, each number corresponds to a dot, (a,b) means an edge connects a and b\n",
    "graphs = [[(0,1)], \n",
    "          [(0,1),(0,1)], [(0,1),(0,2)], \n",
    "          [(0,1),(0,1),(0,1)], [(0,1),(1,2),(0,2)], [(0,1),(0,1),(0,2)], \n",
    "          [(0,1),(0,2),(0,3)], [(0,1),(1,2),(0,3)], \n",
    "          [(0,1),(0,1),(0,1),(0,1)], [(0,1),(0,1),(0,2),(0,2)], [(0,1),(1,2),(1,2),(0,2)], \n",
    "          [(0,1),(0,1),(0,1),(0,2)], [(0,1),(1,2),(2,3),(3,0)], [(0,1),(0,1),(0,2),(0,3)], \n",
    "          [(0,1),(0,1),(0,2),(1,3)], [(0,1),(1,2),(2,3),(3,1)], [(0,1),(0,1),(0,2),(2,3)], \n",
    "          [(0,1),(0,2),(0,3),(0,4)], [(0,1),(0,2),(0,3),(1,4)], [(0,1),(0,2),(1,3),(2,4)], \n",
    "          [(0,1),(0,1),(0,1),(0,1),(0,1)],\n",
    "          [(0,1),(0,2),(1,2),(1,2),(1,2)], [(0,1),(0,1),(0,2),(1,2),(1,2)], \n",
    "          [(0,1),(0,1),(0,1),(0,1),(0,2)], [(0,1),(0,1),(0,1),(0,2),(0,2)], \n",
    "          [(0,1),(0,2),(2,1),(3,1),(3,2)], [(0,1),(0,1),(0,1),(0,3),(0,2)], \n",
    "          [(0,1),(0,1),(0,3),(0,2),(0,2)], [(0,1),(0,1),(0,1),(0,2),(1,3)],\n",
    "          [(0,1),(0,1),(2,1),(2,3),(3,1)], [(0,1),(2,1),(3,1),(3,2),(3,2)],\n",
    "          [(0,1),(2,1),(3,1),(3,2),(1,2)], [(0,1),(0,2),(0,2),(1,3),(1,3)],\n",
    "          [(0,1),(2,1),(3,2),(3,0),(1,2)], [(0,1),(0,1),(0,2),(0,2),(1,3)],\n",
    "          [(0,1),(0,2),(0,2),(0,2),(1,3)], [(0,1),(1,2),(2,3),(3,4),(4,0)],\n",
    "          [(0,1),(0,1),(0,2),(0,3),(0,4)], [(0,1),(0,2),(1,2),(0,3),(0,4)],\n",
    "          [(0,1),(0,1),(1,2),(0,3),(0,4)], [(0,1),(1,2),(1,2),(0,3),(0,4)],\n",
    "          [(0,1),(2,1),(3,1),(3,2),(3,4)], [(0,1),(0,2),(1,3),(3,2),(3,4)],\n",
    "          [(0,1),(0,2),(1,2),(0,3),(3,4)], [(0,1),(0,2),(0,2),(0,3),(1,4)],\n",
    "          [(0,1),(0,1),(1,2),(0,3),(3,4)], [(0,1),(1,2),(1,2),(0,3),(3,4)],\n",
    "          [(0,1),(0,2),(0,3),(0,4),(0,5)], [(0,1),(0,2),(0,3),(1,4),(1,5)],\n",
    "          [(0,1),(0,2),(0,3),(0,4),(1,5)], [(0,1),(0,2),(1,3),(1,4),(2,5)],\n",
    "          [(0,1),(0,2),(0,3),(1,4),(2,5)], [(0,1),(1,2),(0,3),(3,4),(4,5)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating EFPs and print out each runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### the results list will contain 53 lists, each will contain the values of all jets of a single EFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efps = [ef.EFP(graph, measure='hadr', beta=1, normed=True) for graph in graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "print(\"{:15} {:15} {:15}\".format('graph_number','degree','runtime(s)'))\n",
    "for i in range(len(efps)):\n",
    "    results_tmp = []\n",
    "    start = time.time()\n",
    "    for j in range(len(events)):\n",
    "        results_tmp.append(efps[i].compute(events[j]))\n",
    "    end = time.time()\n",
    "    if i<1: deg = 1\n",
    "    elif i<3: deg = 2\n",
    "    elif i<8: deg = 3\n",
    "    elif i<20: deg = 4\n",
    "    elif i<53: deg = 5\n",
    "    else: deg = -999\n",
    "    print(\"{:<15} {:<15} {:<15.03f}\".format(i, deg, end - start))\n",
    "    np_res_tmp = np.array(results_tmp)\n",
    "    results.append(np_res_tmp)\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_results = []\n",
    "\n",
    "print(\"{:15} {:15} {:15}\".format('graph_number','degree','runtime(s)'))\n",
    "for i in range(len(efps)):\n",
    "    results_tmp = []\n",
    "    start = time.time()\n",
    "    for j in range(len(mc_events)):\n",
    "        results_tmp.append(efps[i].compute(mc_events[j]))\n",
    "    end = time.time()\n",
    "    if i<1: deg = 1\n",
    "    elif i<3: deg = 2\n",
    "    elif i<8: deg = 3\n",
    "    elif i<20: deg = 4\n",
    "    elif i<53: deg = 5\n",
    "    else: deg = -999\n",
    "    print(\"{:<15} {:<15} {:<15.03f}\".format(i, deg, end - start))\n",
    "    np_res_tmp = np.array(results_tmp)\n",
    "    mc_results.append(np_res_tmp)\n",
    "mc_results = np.array(mc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize MC by pt distributioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there will be 200 bins, pt from 20 to 120 GeV\n",
    "bins = np.linspace(20, 120, 201)\n",
    "# ..._counts will the a list of bin heights\n",
    "pt_counts, _ =  np.histogram(pttot, bins)\n",
    "mcpt_counts, _ = np.histogram(mc_pttot, bins)\n",
    "# scale_arr is the ratio of the heights\n",
    "scale_arr = np.array(pt_counts)/np.array(mcpt_counts, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the weight list contains the weight of each MC jet for filling histograms \n",
    "weight = []\n",
    "for pt in mc_pttot:\n",
    "    if pt>20 and pt<120:\n",
    "        weight.append(scale_arr[int(pt*2)-40])\n",
    "    else:\n",
    "        weight.append(0)\n",
    "weight = np.array(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The original code to draw the EFP distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the x limit for the histograms\n",
    "xlim = [0.4, 0.15, 0.1, 0.04, 0.02, 0.03, 0.03, 0.02, 0.02, 0.01,\n",
    "        0.01, 0.02, 0.01, 0.015, 0.010, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
    "        0.006, 0.0015, 0.0015, 0.003, 0.003, 0.001, 0.0025, 0.0025, 0.002, 0.001,\n",
    "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.002, 0.001, 0.001,\n",
    "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.002, 0.0005, 0.0005,\n",
    "        0.0005, 0.0005, 0.0005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for the whole pt range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(53):\n",
    "    directory = 'basis_mc_ptscaled/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    fig, (ax, ax1) = plt.subplots(2,1,gridspec_kw={'height_ratios': [3.5, 1]}, figsize=(6,5))\n",
    "    bins = np.linspace(0, xlim[i], 21)\n",
    "    bin_centres = (bins[:-1] + bins[1:])/2\n",
    "    ax.set_xlim(0, xlim[i])\n",
    "    ax1.set_xlim(0, xlim[i])\n",
    "    ax1.set_ylim(0.5,1.5)\n",
    "    \n",
    "    plt.xticks(np.arange(0, xlim[i], xlim[i]/5))\n",
    "    \n",
    "    \n",
    "#         for data\n",
    "    data = results[i][np.logical_and(jetm >= jetm_lb[i], pttot<120)]\n",
    "    counts, _ = np.histogram(data, bins)\n",
    "    err = np.sqrt(counts)\n",
    "    ax.errorbar(bin_centres, counts, yerr=np.sqrt(counts), fmt = 'ok', capsize=3, label = \"data\")\n",
    "#         for mc\n",
    "    mc = mc_results[i][np.logical_and(mc_jetm >= jetm_lb[i], mc_pttot<120)]\n",
    "    weight_new = weight[np.logical_and(mc_jetm >= jetm_lb[i], mc_pttot<120)]\n",
    "    mc_counts, _ = np.histogram(mc, bins, weights = weight_new)\n",
    "    ax.hist(bin_centres, weights = mc_counts, bins = bins, label = \"MC\")\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.legend(prop={'size': 14}, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "#     graphs/ contains the multigraphs\n",
    "    im = plt.imread('graphs/' + str(i) + '.png')\n",
    "    newax = fig.add_axes([0.76, .6, 0.2, 0.2], zorder=1)\n",
    "    newax.imshow(im)\n",
    "    newax.axis('off')\n",
    "#     ratio\n",
    "    counts = counts.astype(float)\n",
    "    ratio = np.divide(counts, mc_counts, out=np.zeros_like(counts), where = mc_counts!=0)\n",
    "    ratio_err = np.divide(err, mc_counts, out=np.zeros_like(counts), where = mc_counts!=0)\n",
    "    ax1.errorbar(bin_centres, ratio, yerr = ratio_err, fmt = '.k', capsize=3)\n",
    "    ax1.set_yticks(np.arange(0.5, 1.5, 0.25), minor=True)\n",
    "    ax1.grid(color='grey', linestyle='--', linewidth=2, axis='y', alpha=0.7, which='both')\n",
    "    ax1.set_xlabel('EFP Value', fontsize = 16)\n",
    "    plt.subplots_adjust(hspace = 0.1)\n",
    "    plt.gcf().subplots_adjust(bottom=0.12)\n",
    "    plt.savefig(directory + str(i) + '.png', dpi = 300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For finer pt ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3) :\n",
    "    for i in range(53):\n",
    "        directory = 'basis_mc_pt_notptscaled/' + str(j) + '/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fig, (ax, ax1) = plt.subplots(2,1,gridspec_kw={'height_ratios': [3.5, 1]}, figsize=(6,5))\n",
    "        lowlim = 20 + 10*j\n",
    "        uplim = 20 + 10*(j+1)\n",
    "        \n",
    "        bins = np.linspace(0, xlim[i]*(1-j*0.2), 11)\n",
    "        bin_centres = (bins[:-1] + bins[1:])/2\n",
    "        plt.xlim(0, xlim[i]*(1-j*0.2))\n",
    "        ax.set_xlim(0, xlim[i]*(1-j*0.2))\n",
    "        ax1.set_xlim(0, xlim[i]*(1-j*0.2))\n",
    "        ax1.set_ylim(0.5,1.5)\n",
    "        plt.xticks(np.arange(0, xlim[i]*(1-j*0.2), xlim[i]*(1-j*0.2)/(5-j)))\n",
    "        \n",
    "#         for data\n",
    "        data = results[i][np.logical_and.reduce((pttot > lowlim, pttot <= uplim, jetm >= jetm_lb[i], pttot<120))]\n",
    "        counts, _ = np.histogram(data, bins)\n",
    "        err = np.sqrt(counts)\n",
    "        ax.errorbar(bin_centres, counts, yerr=np.sqrt(counts), fmt = '.k', capsize=3, label = \"data\")\n",
    "#         for mc\n",
    "        mc = mc_results[i][np.logical_and.reduce((mc_pttot > lowlim, mc_pttot <= uplim, mc_jetm >= jetm_lb[i]))]\n",
    "        mc_counts, _ = np.histogram(mc, bins)    \n",
    "        scaled_mc = len(data)/float(len(mc))*mc_counts\n",
    "        ax.hist(bin_centres, weights = scaled_mc, bins = bins, color = \"mediumseagreen\", label = \"MC\")\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.legend(prop={'size': 14}, loc='upper right')\n",
    "        \n",
    "        plt.figtext(.96, .75, r'jet_pt$\\in$(' + str(lowlim) + ', '+str(uplim)+']', fontsize = 16, ha = 'right')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        im = plt.imread('graphs/' + str(i) + '.png')\n",
    "        newax = fig.add_axes([0.76, .50, 0.2, 0.2], zorder=1)\n",
    "        newax.imshow(im)\n",
    "        newax.axis('off')\n",
    "#         ratio\n",
    "        counts = counts.astype(float)\n",
    "        ratio = np.divide(counts, scaled_mc, out=np.zeros_like(counts), where = scaled_mc!=0)\n",
    "        ratio_err = np.divide(err, scaled_mc, out=np.zeros_like(counts), where = scaled_mc!=0)\n",
    "        ax1.errorbar(bin_centres, ratio, yerr = ratio_err, fmt = '.k', capsize=3)\n",
    "        ax1.set_yticks(np.arange(0.5, 1.5, 0.25), minor=True)\n",
    "        ax1.grid(color='grey', linestyle='--', linewidth=2, axis='y', alpha=0.5, which='both')\n",
    "        plt.subplots_adjust(hspace = 0.1)\n",
    "        \n",
    "        plt.savefig(directory + str(i) + '.png', dpi = 300)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_transposed = results.transpose()\n",
    "for j in range(1,10):\n",
    "#     j is the dimension of the PCA\n",
    "    pca = PCA(n_components=j)\n",
    "#     the results projected onto the PCs (dimension-reduced) represented by the PC basis\n",
    "    results_transformed = pca.fit_transform(results_transposed)\n",
    "#     represent the dimension-reduced results by the EFP (original) basis. it's called \"centered\" because PCA \n",
    "#     will automatically center the data first\n",
    "    centered = np.matmul(results_transformed, pca.components_)\n",
    "#     un-center, results_approx is the approximated results\n",
    "    original_transposed = centered + pca.mean_\n",
    "    results_approx = original_transposed.transpose()\n",
    "    for i in range(53):\n",
    "#   put codes to draw the histograms here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_results = np.zeros_like(results)\n",
    "for i in range(len(results)):\n",
    "    norm_results[i] = (results[i] - np.mean(results[i]))/np.std(results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mass over pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = []\n",
    "i = 0\n",
    "for e in events:\n",
    "    px_tot = py_tot = pz_tot = en_tot = 0\n",
    "    for c in e:\n",
    "        px = c[0]*math.cos(c[2])\n",
    "        py = c[0]*math.sin(c[2])\n",
    "        pz = c[0]*math.sinh(c[1])        \n",
    "        px_tot += px\n",
    "        py_tot += py\n",
    "        pz_tot += pz\n",
    "        en_tot += math.sqrt(px*px + py*py + pz*pz)\n",
    "    tmp = en_tot*en_tot - px_tot*px_tot - py_tot*py_tot - pz_tot*pz_tot\n",
    "    if tmp < 0.0001: \n",
    "#         print(tmp)\n",
    "        tmp = 0\n",
    "    masses.append(math.sqrt(tmp))\n",
    "    i+=1\n",
    "masses = np.array(masses)\n",
    "masses_over_pt = masses/pttot\n",
    "norm_masses_over_pt = (masses_over_pt-np.mean(masses_over_pt))/np.std(masses_over_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linear regression on EFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EFP_dim in [1,5,15,25,35,45,53]:\n",
    "#     EFP_dim is the number of EFP included\n",
    "    trans_res = norm_results[:EFP_dim].transpose()\n",
    "\n",
    "    reg = linear_model.LinearRegression()\n",
    "#     Performing linear regression here\n",
    "    reg.fit(trans_res, norm_masses_over_pt)\n",
    "#     the coefficient of each EFP\n",
    "    w = np.array(reg.coef_)\n",
    "    \n",
    "    mass_efp = []\n",
    "    for i in range(len(trans_res)):\n",
    "#         calculating the masses using the 53 EFPs\n",
    "        mass_efp.append((w*trans_res[i]).sum())\n",
    "\n",
    "#     Place the code to draw the histogram here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linear regression on PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_pca = []\n",
    "trans_res = norm_results[:53].transpose()\n",
    "# pca_comp contains the pc represented by the basis of 53 EFPs\n",
    "pca_comp = pca.components_\n",
    "for i in range(len(trans_res)):\n",
    "    pca_tmp = []\n",
    "    for j in range(len(pca_comp)):\n",
    "#         calculate each jet's projection onto the PCs\n",
    "        pca_tmp.append(np.dot(trans_res[i], pca_comp[j]))\n",
    "    events_pca.append(pca_tmp)\n",
    "events_pca = np.array(events_pca)\n",
    "reg_pca = linear_model.LinearRegression()\n",
    "reg_pca.fit(events_pca, norm_masses_over_pt)\n",
    "mass_pca = []\n",
    "w = np.array(reg_pca.coef_)\n",
    "for i in range(len(events_pca)):\n",
    "    mass_pca.append((w*events_pca[i]).sum())\n",
    "\n",
    "# Place the code to draw the histogram here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The process are the same for other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Girth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_diff(t1,t2):\n",
    "    dphi = abs(t1-t2)\n",
    "    if(dphi >= math.pi):\n",
    "        dphi = 2*math.pi - dphi\n",
    "    return dphi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = []\n",
    "phi = []\n",
    "for e in t:\n",
    "    if e.jetm > 0:\n",
    "        n = e.jetm\n",
    "        if e.pt > 20: \n",
    "            ev = 1\n",
    "            eta.append(e.eta)\n",
    "            phi.append(e.phi)\n",
    "        else: ev = 0\n",
    "    elif n >= 0:\n",
    "        n -= 1\n",
    "eta = np.array(eta)\n",
    "phi = np.array(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girths = []\n",
    "i = 0\n",
    "for e in events:\n",
    "    g = 0\n",
    "    eta_jet = eta[i]\n",
    "    phi_jet = phi[i]\n",
    "    for c in e:\n",
    "        eta_i = c[1]\n",
    "        phi_i = c[2]\n",
    "        g+=c[0]*math.sqrt(theta_diff(eta_i, eta_jet)**2 + theta_diff(phi_i , phi_jet)**2)      \n",
    "        if math.sqrt(theta_diff(eta_i, eta_jet)**2 + theta_diff(phi_i, phi_jet)**2) > 0.5:\n",
    "            print\n",
    "            print(math.sqrt(theta_diff(eta_i, eta_jet)**2 + (phi_i - phi_jet)**2))\n",
    "            print eta_i, eta_jet, phi_i, phi_jet\n",
    "        if g > pttot[i]:\n",
    "            print g, pttot[i]\n",
    "    g /= pttot[i]\n",
    "    girths.append(g)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated Jet Shape $\\Psi(0.1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IJS = []\n",
    "yes = no = 0\n",
    "i = 0\n",
    "for e in events:\n",
    "    psi = 0\n",
    "    eta_jet = eta[i]\n",
    "    phi_jet = phi[i]\n",
    "    for c in e:\n",
    "        eta_i = c[1]\n",
    "        phi_i = c[2]\n",
    "        r = math.sqrt(theta_diff(eta_i, eta_jet)**2 + theta_diff(phi_i, phi_jet)**2)\n",
    "#         if r > 0.05: no += 1\n",
    "        if r <= 0.1:\n",
    "            yes += 1\n",
    "            psi += c[0]\n",
    "        else:\n",
    "            no += 1\n",
    "    psi /= pttot[i]\n",
    "    IJS.append(psi)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
